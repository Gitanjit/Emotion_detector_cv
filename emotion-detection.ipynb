{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/fer2013/fer2013.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion_data = pd.read_csv('/kaggle/input/fer2013/fer2013.csv')\nprint(emotion_data)","execution_count":3,"outputs":[{"output_type":"stream","text":"       emotion                                             pixels        Usage\n0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n...        ...                                                ...          ...\n35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n\n[35887 rows x 3 columns]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion_data = emotion_data[emotion_data['emotion'] != 1]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def num_change(num):\n    if num > 1:\n        return num-1\n    return num\n\nemotion_data['emotion'] = emotion_data['emotion'].apply(num_change)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion_data['emotion'].unique()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"array([0, 1, 3, 5, 2, 4])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion_data['Usage'].unique()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"array(['Training', 'PublicTest', 'PrivateTest'], dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = []\ny_train = []\nX_test = []\ny_test = []\nfor index, row in emotion_data.iterrows():\n    k = row['pixels'].split(\" \")\n    if row['Usage'] == 'Training':\n        X_train.append(np.array(k))\n        y_train.append(row['emotion'])\n    elif row['Usage'] == 'PublicTest':\n        X_test.append(np.array(k))\n        y_test.append(row['emotion'])","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(X_train)\ny_train = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)\n\nfrom keras.utils import np_utils\nX_train = X_train.reshape(X_train.shape[0], 48, 48, 1).astype('float64')\nX_test = X_test.reshape(X_test.shape[0], 48, 48, 1).astype('float64')\n\ny_train= np_utils.to_categorical(y_train, num_classes=6).astype('float64')\ny_test = np_utils.to_categorical(y_test, num_classes=6).astype('float64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features = 64\nnum_labels = 6\nbatch_size = 64\nepochs = 100\nwidth, height = 48, 48","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1), kernel_regularizer=l2(0.01)))\nmodel.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(2*2*2*num_features, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(2*2*num_features, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(2*num_features, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_labels, activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=categorical_crossentropy,\n              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train,\n                    validation_data=(X_test, y_test),\n                    batch_size=64,\n                    epochs=33,\n                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fer_json = model.to_json()\nwith open(\"fer.json\", \"w\") as json_file:\n    json_file.write(fer_json)\nmodel.save_weights(\"fer.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}